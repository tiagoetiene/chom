#!/usr/bin/env node

_ = require("underscore");
MongoClient = require('mongodb').MongoClient;
ObjectID = require('mongodb').ObjectID;

args = require('./save/args');
utils = require('./libs/utils');

// Input arguments
var inputDatabase = program.database;
var inputKeys = program.keys;
var inputCode = ( program.code ) ? Function( "datum", program.code ) : undefined;
var inputMaxBufferSize = program.max;
var inputSaveInterval = program.saveInterval;
var inputSimulate = ( program.simulate ) ? true : false;
var inputInsert = ( program.insert ) ? true : false;
var inputCastField = _.filter( program.cast, function( value, idx ) { 
	return idx % 2 == 0; 
} ) ;
var inputCastType = _.filter( program.cast, function( value, idx ) { 
	return idx % 2 == 1; 
} ) ;

process.stderr.write("\n");
process.stderr.write( "* chom-save" + "\n");
process.stderr.write( "  * parameters settings:\n");
process.stderr.write( "    * database  : " + JSON.stringify( inputDatabase ) + "\n" );
process.stderr.write( "    * code      : " + program.code + "\n" );
process.stderr.write( "    * keys      : " + inputKeys + "\n" );
process.stderr.write( "    * max buffer: " + inputMaxBufferSize + "\n" );
process.stderr.write( "    * save inter: " + inputSaveInterval + "\n" );
process.stderr.write( "    * simulate  : " + inputSimulate + "\n" );
process.stderr.write("\n");


if( _.isEmpty( program.collection ) != true ) {
	inputDatabase.collection = program.collection;
}

if( !inputDatabase ) {
	process.stderr.write( "  * Missing database information" );
	process.stderr.write( " (--config config.json)\n" );
	program.help();
}

if( !inputKeys ) {
	inputKeys = [];
	process.stderr.write( "  * Missing key(s) to be used.");
	process.stderr.write( " Defaulting to \"--keys _id --cast _id,objectid\"\n" );

	inputKeys.push( "_id" );
	inputCastField.push( "_id" );
	inputCastType.push( "objectid" );
}

var database;
var queue = {};
var timestamp = [];
var isSaving = false;

MongoClient.connect( inputDatabase.mongo_url, function( err, db ) {

	if( err )  {
		console.log( '* Error found while connecting to the database:', err );
		throw err;
	}
	database = db;

	var collection = database.collection( inputDatabase.collection );

	setInterval( function() { 

		//
		// If we are in the process of saving data to the database,
		// let's to start saving more data and overloaded the
		// server in the process
		//
		if( isSaving == true )
			return;


		//
		// Ok, we will start a potentially expensive operation
		// Setting isSaving to true will lock the network communication
		// for the current data in queue
		//
		isSaving = true;

		//
		// MongoDB bullk operation. We don't care about the order
		// in which the data is save.
		//
		var bulkOperations = collection.initializeUnorderedBulkOp();

		//
		// Counting operation. We do not want to call .execute()
		// if we do not have to
		//
		var operationCounter = 0;

		//
		// For each element in queue, let's schedule
		// an operation
		//
		_.each( queue, function( value, key ) {

			if( value.modified ) {

				var datum = _.extend( {}, value )
				delete datum[ "modified" ];

				if( inputInsert ) {

					if( inputSimulate == false )
						bulkOperations.insert( datum );

				} else {

					//  If we wish to update the date, then
					// we must build a query based on keys
					var query = { };
					_.each( inputKeys, function( key ) {
						query[ key ] = datum[ key ];
						delete datum[ key ];
					} );

					if( inputSimulate == false )
						bulkOperations.find( query ).upsert().updateOne( { $set : datum } );	
				}

				if( inputSimulate == false )
					operationCounter++;

				if( inputSimulate == true )
					console.log( query, datum );
			}
		} );

		if( operationCounter == 0 ) {

			// 
			// If no operation was scheduled, let's continue
			//
			isSaving = false;

		} else {

			//
			// Marking everything as modified
			// 
			_.each( queue, function( value, key ) { value.modified = false; } );

			//
			// Let's try to save the data, if for some reason it doesn't succeed,
			// then print the error
			//
			try {
				var timeout = 5000000;

				bulkOperations.execute( { w: 1, wtimeout : timeout }, function( err, ret ) {
					if( err ) 
						console.log( "* error: ", err );
					
					isSaving = false;
				} );

			} catch ( err ) {

				console.log( "* exception ", err );
				
				//
				// If a error accurs, we discard whatever was in the queue 
				// up until this point, restart bulk operations, and set 
				// isRunning to false
				// 
				isSaving = false;
			}
		}
	}, inputSaveInterval );
});

function getKey( datum ) {
	var key = "";
	_.each( inputKeys, function( k, idx ) { 
		key += JSON.stringify( datum[ k ] ); 
		if( idx < inputKeys.length-1 )
			key += ",";
	} );
	return key;
}

function fixKeys( datum ) {
	_.each( inputKeys, function( key ) {
		if( _.has( datum, key ) == false )
			datum[ key ] = new ObjectID();
	} );
}

function cast( datum ) {

	_.each( inputCastField, function( field, idx ) {
		if( _.isEqual( inputCastType[ idx ].toLowerCase(), "date" ) == true ) {
			datum[ field ] = new Date( datum[ field ] );
		} else if( _.isEqual( inputCastType[ idx ].toLowerCase(), "objectid" ) ) {
			datum[ field ] = new ObjectID( datum[ field ] )
		} else {
			console.assert( 0 && "no such type" );
		}
	} );

}

function runCode( datum ) {

	if( inputCode ) {
		inputCode( datum );
	}

}

function exitWhenReady() {

	setInterval( function() {

		//
		// Checking whether we are currently
		// saving any date. If we are, then
		// we cannot exit the process just
		// yet
		//
		if( isSaving === true )
			return;

		//
		// Now we check whether there's still
		// work to be done. In other words,
		// we check whether there are modified
		// data. If there are data to be saved,
		// then we cannot exit the process just
		// yet
		//
		var stillHasWorkToDo = false;
		_.each( queue, function( value, key ) { 
			if( value.modified ) {
				stillHasWorkToDo = true;
			 }
		} );

		if( stillHasWorkToDo == true )
			return;

		//
		// Ok, everything was sabed to the database.
		// We can now gracefully finish the current
		// process
		//
		process.stderr.write("* chom-save close\n");
		database.close();
		process.exit();	

	}, 2000);
}

utils.readJSONFromSTDIN( function( datum ) {

	if( _.isEmpty( datum ) ) {

		exitWhenReady();

		return;
	}

	//
	// If some key is missing, we add them back
	//
	fixKeys( datum );


	//
	// If user wants to cast some field to
	// some type, then this will happen here 
	//
	cast( datum );

	//
	//  If user wants to run custom code,
	//  then, it will happen here
	//
	runCode( datum );

	//
	// Keeping the queue to a maximum size
	// in order to avoid explosion memory use
	//
	if( inputMaxBufferSize != 0 ) {

		while( _.size(  queue ) >= inputMaxBufferSize ) {
			if( queue[ timestamp[ 0 ] ].modified == false )
				delete queue[ timestamp.shift() ];
			else 
				break;
		}
	}
	

	//
	// Extracting key from data
	//
	var key = getKey( datum );
	var keyExists = false;
	
	
	//
	// If the key already exists, then
	// let mark it as modified
	//
	if( _.has( queue, key ) ) {
		keyExists = true;
		datum.modified = queue[ key ].modified;
	}	

	//
	// If new data is different from old data, 
	// then update it
	//
	if( _.isEqual( queue[ key ], datum ) == false ) {
		datum.modified = true;
		queue[ key ] = datum;

		if( inputMaxBufferSize != 0 && keyExists == false ) {

			//
			// Saving the order in which data is inserted
			// Old data gets removed if inputMaxBufferSize
			// is reached
			//
			timestamp.push( key );	
		}
	}

} );
