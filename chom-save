#!/usr/bin/env node

HashMap = require('hashmap').HashMap;
_ = require("underscore");
MongoClient = require('mongodb').MongoClient;
ObjectID = require('mongodb').ObjectID;

args = require('./save/args');
utils = require('./libs/utils');

// Input arguments
var inputDatabase = program.database;
var inputKeys = program.keys;
var inputCode = ( program.code ) ? Function( "datum", program.code ) : undefined;
var inputMaxBufferSize = program.max;
var inputSaveInterval = program.saveInterval;
var inputSimulate = ( program.simulate ) ? true : false;
var inputInsert = ( program.insert ) ? true : false;
var inputCastField = _.filter( program.cast, function( value, idx ) { 
	return idx % 2 == 0; 
} ) ;
var inputCastType = _.filter( program.cast, function( value, idx ) { 
	return idx % 2 == 1; 
} ) ;

process.stderr.write("\n");
process.stderr.write( "* chom-save" + "\n");
process.stderr.write( "  * parameters settings:\n");
process.stderr.write( "    * database  : " + JSON.stringify( inputDatabase ) + "\n" );
process.stderr.write( "    * code      : " + program.code + "\n" );
process.stderr.write( "    * keys      : " + JSON.stringify( inputKeys ) + "\n" );
process.stderr.write( "    * max buffer: " + inputMaxBufferSize + "\n" );
process.stderr.write( "    * save inter: " + inputSaveInterval + "\n" );
process.stderr.write( "    * simulate  : " + inputSimulate + "\n" );
process.stderr.write("\n");


if( _.isEmpty( program.collection ) != true ) {
	inputDatabase.collection = program.collection;
}

if( !inputDatabase ) {
	process.stderr.write( "  * Missing database information" );
	process.stderr.write( " (--config config.json)\n" );
	program.help();
}

if( !inputKeys ) {
	inputKeys = [];
	process.stderr.write( "  * Missing key(s) to be used.");
	process.stderr.write( " Defaulting to \"--keys _id --cast _id,objectid\"\n" );

	inputKeys.push( "_id" );
	inputCastField.push( "_id" );
	inputCastType.push( "objectid" );
}

var database;
var queue = new HashMap();
var isSaving = false;

MongoClient.connect( inputDatabase.mongo_url, function( err, db ) {

	if( err )  {
		console.log( '* Error found while connecting to the database:', err );
		throw err;
	}
	database = db;

	var collection = database.collection( inputDatabase.collection );

	setInterval( function() { 

		// process.stderr.write("\t----\n");

		//
		// If we are in the process of saving data to the database,
		// let's to start saving more data and overloaded the
		// server in the process
		//
		if( isSaving == true )
			return;

		// process.stderr.write("\tA\n");

		//
		// Ok, we will start a potentially expensive operation
		// Setting isSaving to true will lock the network communication
		// for the current data in queue
		//
		isSaving = true;

		//
		// MongoDB bullk operation. We don't care about the order
		// in which the data is save.
		//
		var bulkOperations = collection.initializeUnorderedBulkOp();

		//
		// Counting operation. We do not want to call .execute()
		// if we do not have to
		//
		var operationCounter = 0;

		// process.stderr.write("\tB\n");

		//
		// For each element in queue, let's schedule
		// an operation
		//
		queue.forEach( function( value, key ) {

			if( value.modified ) {

				value.modified = false;

				var datum = _.extend( {}, value )
				delete datum[ "modified" ];

				if( inputInsert ) {

					if( inputSimulate == false )
						bulkOperations.insert( datum );

				} else {

					//  If we wish to update the date, then
					// we must build a query based on keys
					var query = { };
					_.each( inputKeys, function( key ) {
						query[ key ] = datum[ key ];
						delete datum[ key ];
					} );

					if( inputSimulate == false )
						bulkOperations.find( query ).upsert().updateOne( { $set : datum } );	
				}

				queue.remove( key );

				operationCounter++;

				if( inputSimulate == true )
					console.log( query, datum );
			}
		} );

		// process.stderr.write("\tC\n");

		// process.stderr.write("* Operations: " + operationCounter + "\n" );
		if( operationCounter == 0 ) {

			// 
			// If no operation was scheduled, let's continue
			//
			isSaving = false;

		} else {

			// process.stderr.write("\t* Saving: " + JSON.stringify( new Date() ) + "\n" );

			if( inputSimulate == false ) {
				//
				// Let's try to save the data, if for some reason it doesn't succeed,
				// then print the error
				//
				try {
					var timeout = 5000000;

					bulkOperations.execute( { w: 1, wtimeout : timeout }, 
						function( err, ret ) {
							if( err ) {
								process.stderr.write( "* error: " + JSON.stringify( err ) );
							}
							
							isSaving = false;
						} );

				} catch ( e ) {

					process.stderr.write( "* exception: " + JSON.stringify( e ) );
					
					//
					// If a error accurs, we discard whatever was in the queue 
					// up until this point, restart bulk operations, and set 
					// isRunning to false
					// 
					isSaving = false;
				}
			} else {
				isSaving = false;
			}
		}
		// process.stderr.write("\tD\n");
	}, inputSaveInterval );
});

function getKey( datum ) {
	var key = {};
	_.each( inputKeys, function( k, idx ) { 
			key[ k ] += datum[ k ];
	} );
	console.assert( _.isUndefined( key ) == false );
	console.assert( _.isNull( key ) == false );
	return key;
}

function fixKeys( datum ) {
	_.each( inputKeys, function( key ) {
		if( _.has( datum, key ) == false ) {
			process.stderr.write("Cannot found keys for " + JSON.stringify( datum ) );
			datum[ key ] = new ObjectID();
		}
	} );
}

function cast( datum ) {

	_.each( inputCastField, function( field, idx ) {
		if( _.isEqual( inputCastType[ idx ].toLowerCase(), "date" ) == true ) {
			datum[ field ] = new Date( datum[ field ] );
		} else if( _.isEqual( inputCastType[ idx ].toLowerCase(), "objectid" ) ) {
			datum[ field ] = new ObjectID( datum[ field ] )
		} else {
			console.assert( 0 && "no such type" );
		}
	} );

}

function runCode( datum ) {

	if( inputCode ) {
		inputCode( datum );
	}

}

function exitWhenReady() {

	setInterval( function() {

		//
		// Checking whether we are currently
		// saving any date. If we are, then
		// we cannot exit the process just
		// yet
		//
		if( isSaving === true )
			return;

		//
		// Now we check whether there's still
		// work to be done. In other words,
		// we check whether there are modified
		// data. If there are data to be saved,
		// then we cannot exit the process just
		// yet
		//
		var stillHasWorkToDo = false;
		queue.forEach( function( value, key ) { 
			if( value.modified ) {
				stillHasWorkToDo = true;
			 }
		} );

		if( stillHasWorkToDo == true )
			return;

		//
		// Ok, everything was sabed to the database.
		// We can now gracefully finish the current
		// process
		//
		process.stderr.write("* chom-save close\n");
		database.close();
		process.exit();	

	}, 2000);
}

utils.readJSONFromSTDIN( function( datum ) {

	// process.stderr.write("I");

	if( _.isEmpty( datum ) ) {

		exitWhenReady();

		return;
	}

	// process.stderr.write("II\n");

	//
	// If some key is missing, we add them back
	//
	fixKeys( datum );

	// process.stderr.write("III\n");


	//
	// If user wants to cast some field to
	// some type, then this will happen here 
	//
	cast( datum );

	// process.stderr.write("IV\n");

	//
	//  If user wants to run custom code,
	//  then, it will happen here
	//
	runCode( datum );
	

	//
	// Extracting key from data
	//
	var key = getKey( datum );
	var keyExists = false;
	
	
// process.stderr.write("VIII\n");

	//
	// If the key already exists, then
	// let mark it as modified
	//
	if( queue.has( key ) ) {
		keyExists = true;
		delete queue.get( key )["modified"]
	}	else {
		queue.set( key, {} );
	}

	// process.stderr.write("IX\n");

	//
	// If new data is different from old data, 
	// then update it
	//

	if( _.isEqual( queue.get( key ), datum ) == false ) {
		datum.modified = true;
		queue.set( key , datum );
	}

	// process.stderr.write("X\n");

} );
